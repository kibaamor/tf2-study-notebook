{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to /root/.config/pip/pip.conf\n",
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple/\n",
      "Requirement already up-to-date: pip in /usr/local/lib/python3.6/dist-packages (20.2.4)\n",
      "pip 20.2.4 from /usr/local/lib/python3.6/dist-packages/pip (python 3.6)\n",
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple/\n",
      "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (0.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (1.1.3)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.23.2)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.18.5)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.5.3)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (0.17.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip config set global.index-url https://mirrors.aliyun.com/pypi/simple/\n",
    "!python -m pip install -U pip\n",
    "!pip -V\n",
    "!pip install sklearn pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n",
      "sys.version_info(major=3, minor=6, micro=9, releaselevel='final', serial=0)\n",
      "matplotlib 3.3.2\n",
      "numpy 1.18.5\n",
      "pandas 1.1.3\n",
      "sklearn 0.23.2\n",
      "tensorflow 2.3.1\n",
      "tensorflow.keras 2.4.0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)\n",
    "print(sys.version_info)\n",
    "for module in mpl, np, pd, sklearn, tf, keras:\n",
    "    print(module.__name__, module.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   survived     sex   age  n_siblings_spouses  parch     fare  class     deck  \\\n",
      "0         0    male  22.0                   1      0   7.2500  Third  unknown   \n",
      "1         1  female  38.0                   1      0  71.2833  First        C   \n",
      "2         1  female  26.0                   0      0   7.9250  Third  unknown   \n",
      "3         1  female  35.0                   1      0  53.1000  First        C   \n",
      "4         0    male  28.0                   0      0   8.4583  Third  unknown   \n",
      "\n",
      "   embark_town alone  \n",
      "0  Southampton     n  \n",
      "1    Cherbourg     n  \n",
      "2  Southampton     y  \n",
      "3  Southampton     n  \n",
      "4   Queenstown     y  \n",
      "   survived     sex   age  n_siblings_spouses  parch     fare   class  \\\n",
      "0         0    male  35.0                   0      0   8.0500   Third   \n",
      "1         0    male  54.0                   0      0  51.8625   First   \n",
      "2         1  female  58.0                   0      0  26.5500   First   \n",
      "3         1  female  55.0                   0      0  16.0000  Second   \n",
      "4         1    male  34.0                   0      0  13.0000  Second   \n",
      "\n",
      "      deck  embark_town alone  \n",
      "0  unknown  Southampton     y  \n",
      "1        E  Southampton     y  \n",
      "2        C  Southampton     y  \n",
      "3  unknown  Southampton     y  \n",
      "4        D  Southampton     y  \n"
     ]
    }
   ],
   "source": [
    "# https://storage.googleapis.com/tf-datasets/titanic/train.csv\n",
    "# https://storage.googleapis.com/tf-datasets/titanic/eval.csv\n",
    "\n",
    "train_file = './data/titanic/train.csv'\n",
    "eval_file = './data/titanic/eval.csv'\n",
    "\n",
    "train_df = pd.read_csv(train_file)\n",
    "eval_df = pd.read_csv(eval_file)\n",
    "\n",
    "print(train_df.head())\n",
    "print(eval_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      sex   age  n_siblings_spouses  parch     fare  class     deck  \\\n",
      "0    male  22.0                   1      0   7.2500  Third  unknown   \n",
      "1  female  38.0                   1      0  71.2833  First        C   \n",
      "2  female  26.0                   0      0   7.9250  Third  unknown   \n",
      "3  female  35.0                   1      0  53.1000  First        C   \n",
      "4    male  28.0                   0      0   8.4583  Third  unknown   \n",
      "\n",
      "   embark_town alone  \n",
      "0  Southampton     n  \n",
      "1    Cherbourg     n  \n",
      "2  Southampton     y  \n",
      "3  Southampton     n  \n",
      "4   Queenstown     y  \n",
      "      sex   age  n_siblings_spouses  parch     fare   class     deck  \\\n",
      "0    male  35.0                   0      0   8.0500   Third  unknown   \n",
      "1    male  54.0                   0      0  51.8625   First        E   \n",
      "2  female  58.0                   0      0  26.5500   First        C   \n",
      "3  female  55.0                   0      0  16.0000  Second  unknown   \n",
      "4    male  34.0                   0      0  13.0000  Second        D   \n",
      "\n",
      "   embark_town alone  \n",
      "0  Southampton     y  \n",
      "1  Southampton     y  \n",
      "2  Southampton     y  \n",
      "3  Southampton     y  \n",
      "4  Southampton     y  \n",
      "0    0\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    0\n",
      "Name: survived, dtype: int64\n",
      "0    0\n",
      "1    0\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "Name: survived, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "y_train = train_df.pop('survived')\n",
    "y_eval = eval_df.pop('survived')\n",
    "\n",
    "print(train_df.head())\n",
    "print(eval_df.head())\n",
    "print(y_train.head())\n",
    "print(y_eval.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>n_siblings_spouses</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>627.000000</td>\n",
       "      <td>627.000000</td>\n",
       "      <td>627.000000</td>\n",
       "      <td>627.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>29.631308</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.379585</td>\n",
       "      <td>34.385399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.511818</td>\n",
       "      <td>1.151090</td>\n",
       "      <td>0.792999</td>\n",
       "      <td>54.597730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.895800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.045800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.387500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age  n_siblings_spouses       parch        fare\n",
       "count  627.000000          627.000000  627.000000  627.000000\n",
       "mean    29.631308            0.545455    0.379585   34.385399\n",
       "std     12.511818            1.151090    0.792999   54.597730\n",
       "min      0.750000            0.000000    0.000000    0.000000\n",
       "25%     23.000000            0.000000    0.000000    7.895800\n",
       "50%     28.000000            0.000000    0.000000   15.045800\n",
       "75%     35.000000            1.000000    0.000000   31.387500\n",
       "max     80.000000            8.000000    5.000000  512.329200"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(627, 9) (264, 9)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape, eval_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df.age.hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df.sex.value_counts().plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df['class'].value_counts().plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='sex'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.concat([train_df, y_train], axis=1).groupby('sex').survived.mean().plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex ['male' 'female']\n",
      "n_siblings_spouses [1 0 3 4 2 5 8]\n",
      "parch [0 1 2 5 3 4]\n",
      "class ['Third' 'First' 'Second']\n",
      "deck ['unknown' 'C' 'G' 'A' 'B' 'D' 'F' 'E']\n",
      "embark_town ['Southampton' 'Cherbourg' 'Queenstown' 'unknown']\n",
      "alone ['n' 'y']\n",
      "[IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='sex', vocabulary_list=('male', 'female'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n",
      " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='n_siblings_spouses', vocabulary_list=(1, 0, 3, 4, 2, 5, 8), dtype=tf.int64, default_value=-1, num_oov_buckets=0)),\n",
      " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='parch', vocabulary_list=(0, 1, 2, 5, 3, 4), dtype=tf.int64, default_value=-1, num_oov_buckets=0)),\n",
      " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='class', vocabulary_list=('Third', 'First', 'Second'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n",
      " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='deck', vocabulary_list=('unknown', 'C', 'G', 'A', 'B', 'D', 'F', 'E'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n",
      " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='embark_town', vocabulary_list=('Southampton', 'Cherbourg', 'Queenstown', 'unknown'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n",
      " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='alone', vocabulary_list=('n', 'y'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n",
      " NumericColumn(key='age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
      " NumericColumn(key='fare', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n"
     ]
    }
   ],
   "source": [
    "categorical_columns = ['sex', 'n_siblings_spouses', 'parch', 'class', \n",
    "                       'deck', 'embark_town', 'alone']\n",
    "numeric_columns = ['age', 'fare']\n",
    "\n",
    "feature_columns = []\n",
    "for categorical_column in categorical_columns:\n",
    "    vocab = train_df[categorical_column].unique()\n",
    "    print(categorical_column, vocab)\n",
    "    feature_columns.append(\n",
    "        tf.feature_column.indicator_column(\n",
    "            tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "                categorical_column, vocab)))\n",
    "\n",
    "for numeric_column in numeric_columns:\n",
    "    feature_columns.append(\n",
    "        tf.feature_column.numeric_column(\n",
    "            numeric_column, dtype=tf.float32))\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(data_df, label_df, epochs = 10, shuffle = True, batch_size = 32):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        (dict(data_df), label_df))\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(10000)\n",
    "    dataset = dataset.repeat(epochs).batch(batch_size)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = make_dataset(train_df, y_train, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sex': <tf.Tensor: shape=(5,), dtype=string, numpy=array([b'female', b'male', b'female', b'female', b'male'], dtype=object)>, 'age': <tf.Tensor: shape=(5,), dtype=float64, numpy=array([28., 34., 28., 30., 24.])>, 'n_siblings_spouses': <tf.Tensor: shape=(5,), dtype=int64, numpy=array([1, 1, 1, 3, 0])>, 'parch': <tf.Tensor: shape=(5,), dtype=int64, numpy=array([0, 1, 0, 0, 0])>, 'fare': <tf.Tensor: shape=(5,), dtype=float64, numpy=array([14.4542, 14.4   , 51.8625, 21.    ,  8.05  ])>, 'class': <tf.Tensor: shape=(5,), dtype=string, numpy=array([b'Third', b'Third', b'First', b'Second', b'Third'], dtype=object)>, 'deck': <tf.Tensor: shape=(5,), dtype=string, numpy=array([b'unknown', b'unknown', b'D', b'unknown', b'unknown'], dtype=object)>, 'embark_town': <tf.Tensor: shape=(5,), dtype=string, numpy=\n",
      "array([b'Cherbourg', b'Southampton', b'Southampton', b'Southampton',\n",
      "       b'Southampton'], dtype=object)>, 'alone': <tf.Tensor: shape=(5,), dtype=string, numpy=array([b'n', b'n', b'n', b'n', b'y'], dtype=object)>} tf.Tensor([0 0 1 1 0], shape=(5,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_dataset.take(1):\n",
    "    print(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sex': <tf.Tensor: shape=(5,), dtype=string, numpy=array([b'male', b'male', b'male', b'male', b'male'], dtype=object)>, 'age': <tf.Tensor: shape=(5,), dtype=float64, numpy=array([28., 18., 62., 27., 17.])>, 'n_siblings_spouses': <tf.Tensor: shape=(5,), dtype=int64, numpy=array([0, 1, 0, 0, 0])>, 'parch': <tf.Tensor: shape=(5,), dtype=int64, numpy=array([0, 1, 0, 0, 2])>, 'fare': <tf.Tensor: shape=(5,), dtype=float64, numpy=array([  7.8958,  20.2125,  10.5   ,   7.8958, 110.8833])>, 'class': <tf.Tensor: shape=(5,), dtype=string, numpy=array([b'Third', b'Third', b'Second', b'Third', b'First'], dtype=object)>, 'deck': <tf.Tensor: shape=(5,), dtype=string, numpy=array([b'unknown', b'unknown', b'unknown', b'unknown', b'C'], dtype=object)>, 'embark_town': <tf.Tensor: shape=(5,), dtype=string, numpy=\n",
      "array([b'Southampton', b'Southampton', b'Southampton', b'Southampton',\n",
      "       b'Cherbourg'], dtype=object)>, 'alone': <tf.Tensor: shape=(5,), dtype=string, numpy=array([b'y', b'n', b'y', b'y', b'n'], dtype=object)>} tf.Tensor([0 0 1 0 1], shape=(5,), dtype=int64)\n",
      "WARNING:tensorflow:Layer dense_features is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "[[28.]\n",
      " [18.]\n",
      " [62.]\n",
      " [27.]\n",
      " [17.]]\n",
      "WARNING:tensorflow:Layer dense_features_1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# keras.layers.DenseFeature\n",
    "for x,y in train_dataset.take(1):\n",
    "    print(x, y)\n",
    "    age_column = feature_columns[7]\n",
    "    gender_column = feature_columns[0]\n",
    "    print(keras.layers.DenseFeatures(age_column)(x).numpy())\n",
    "    print(keras.layers.DenseFeatures(gender_column)(x).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer dense_features_2 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "[[ 9.     1.     0.     1.     0.     0.     1.     0.     0.     0.\n",
      "   0.     0.     0.     0.     1.     0.     0.     0.    31.275  0.\n",
      "   0.     0.     1.     0.     0.     0.     0.     0.     1.     0.\n",
      "   0.     0.     0.     1.   ]\n",
      " [18.     1.     0.     0.     0.     1.     1.     0.     0.     0.\n",
      "   0.     0.     0.     0.     1.     0.     0.     0.    23.     0.\n",
      "   1.     0.     0.     0.     0.     0.     0.     1.     0.     0.\n",
      "   0.     0.     0.     1.   ]\n",
      " [28.     0.     1.     1.     0.     0.     1.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     1.     0.     7.75   0.\n",
      "   1.     0.     0.     0.     0.     0.     1.     0.     0.     0.\n",
      "   0.     0.     1.     0.   ]\n",
      " [22.     1.     0.     1.     0.     0.     1.     0.     0.     0.\n",
      "   0.     0.     0.     0.     1.     0.     0.     0.     7.25   1.\n",
      "   0.     0.     0.     0.     0.     0.     1.     0.     0.     0.\n",
      "   0.     0.     1.     0.   ]\n",
      " [17.     0.     1.     1.     0.     0.     1.     0.     0.     0.\n",
      "   0.     0.     0.     0.     1.     0.     0.     0.     7.125  0.\n",
      "   1.     0.     0.     0.     0.     0.     1.     0.     0.     0.\n",
      "   0.     0.     1.     0.   ]]\n"
     ]
    }
   ],
   "source": [
    "# keras.layers.DenseFeature\n",
    "for x,y in train_dataset.take(1):\n",
    "    print(keras.layers.DenseFeatures(feature_columns)(x).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.DenseFeatures(feature_columns),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dense(2, activation='softmax'),\n",
    "])\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "             optimizer = keras.optimizers.SGD(lr=0.01),\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'sex': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=string>, 'age': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float64>, 'n_siblings_spouses': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=int64>, 'parch': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=int64>, 'fare': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float64>, 'class': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=string>, 'deck': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=string>, 'embark_town': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=string>, 'alone': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=string>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layer dense_features_3 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'sex': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=string>, 'age': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float64>, 'n_siblings_spouses': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=int64>, 'parch': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=int64>, 'fare': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float64>, 'class': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=string>, 'deck': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=string>, 'embark_town': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=string>, 'alone': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=string>}\n",
      "Consider rewriting this model with the Functional API.\n",
      " 1/20 [>.............................] - ETA: 0s - loss: 1.1665 - accuracy: 0.7500WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'sex': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=string>, 'age': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float64>, 'n_siblings_spouses': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=int64>, 'parch': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=int64>, 'fare': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float64>, 'class': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=string>, 'deck': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=string>, 'embark_town': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=string>, 'alone': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=string>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 1.9539 - accuracy: 0.6187 - val_loss: 0.6552 - val_accuracy: 0.6680\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6991 - accuracy: 0.6578 - val_loss: 0.6239 - val_accuracy: 0.6523\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6381 - accuracy: 0.6531 - val_loss: 0.6301 - val_accuracy: 0.6719\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6781 - accuracy: 0.6641 - val_loss: 0.5886 - val_accuracy: 0.6680\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6233 - accuracy: 0.6828 - val_loss: 0.6376 - val_accuracy: 0.6250\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6048 - accuracy: 0.6844 - val_loss: 0.6250 - val_accuracy: 0.6406\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6172 - accuracy: 0.6734 - val_loss: 0.5727 - val_accuracy: 0.6953\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6028 - accuracy: 0.6750 - val_loss: 0.6032 - val_accuracy: 0.6914\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5765 - accuracy: 0.6875 - val_loss: 0.5598 - val_accuracy: 0.6953\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5832 - accuracy: 0.7203 - val_loss: 0.5836 - val_accuracy: 0.6328\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5462 - accuracy: 0.7266 - val_loss: 0.5562 - val_accuracy: 0.7070\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6096 - accuracy: 0.7031 - val_loss: 0.5588 - val_accuracy: 0.7031\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5646 - accuracy: 0.7125 - val_loss: 0.5823 - val_accuracy: 0.6953\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5850 - accuracy: 0.6875 - val_loss: 0.5518 - val_accuracy: 0.7031\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5541 - accuracy: 0.7047 - val_loss: 0.5894 - val_accuracy: 0.6953\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5787 - accuracy: 0.6906 - val_loss: 0.5584 - val_accuracy: 0.7266\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5890 - accuracy: 0.6734 - val_loss: 0.5504 - val_accuracy: 0.7031\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5409 - accuracy: 0.7344 - val_loss: 0.5745 - val_accuracy: 0.7109\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5540 - accuracy: 0.7109 - val_loss: 0.5457 - val_accuracy: 0.6992\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5685 - accuracy: 0.7063 - val_loss: 0.6705 - val_accuracy: 0.6445\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5949 - accuracy: 0.7063 - val_loss: 0.5450 - val_accuracy: 0.7109\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5871 - accuracy: 0.7234 - val_loss: 0.6116 - val_accuracy: 0.7109\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5467 - accuracy: 0.7312 - val_loss: 0.5593 - val_accuracy: 0.7109\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5809 - accuracy: 0.6953 - val_loss: 0.5437 - val_accuracy: 0.7109\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5822 - accuracy: 0.7188 - val_loss: 0.5513 - val_accuracy: 0.7031\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5501 - accuracy: 0.7266 - val_loss: 0.5544 - val_accuracy: 0.6602\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5597 - accuracy: 0.7234 - val_loss: 0.5554 - val_accuracy: 0.6758\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5464 - accuracy: 0.7156 - val_loss: 0.5742 - val_accuracy: 0.6992\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5842 - accuracy: 0.6984 - val_loss: 0.5411 - val_accuracy: 0.7109\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5923 - accuracy: 0.7078 - val_loss: 0.5392 - val_accuracy: 0.7109\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5364 - accuracy: 0.7547 - val_loss: 0.5904 - val_accuracy: 0.7070\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5571 - accuracy: 0.7203 - val_loss: 0.5621 - val_accuracy: 0.7148\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5799 - accuracy: 0.7172 - val_loss: 0.6112 - val_accuracy: 0.7148\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5510 - accuracy: 0.7344 - val_loss: 0.6478 - val_accuracy: 0.6836\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5633 - accuracy: 0.7219 - val_loss: 0.5724 - val_accuracy: 0.6953\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5271 - accuracy: 0.7531 - val_loss: 0.5518 - val_accuracy: 0.7344\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5519 - accuracy: 0.7078 - val_loss: 0.5360 - val_accuracy: 0.7305\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5392 - accuracy: 0.7297 - val_loss: 0.5437 - val_accuracy: 0.7188\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5488 - accuracy: 0.7391 - val_loss: 0.5179 - val_accuracy: 0.7266\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5516 - accuracy: 0.7234 - val_loss: 0.5129 - val_accuracy: 0.7500\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5510 - accuracy: 0.7250 - val_loss: 0.5174 - val_accuracy: 0.7344\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5594 - accuracy: 0.7250 - val_loss: 0.5141 - val_accuracy: 0.7461\n",
      "Epoch 43/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5167 - accuracy: 0.7422 - val_loss: 0.6215 - val_accuracy: 0.7031\n",
      "Epoch 44/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5281 - accuracy: 0.7531 - val_loss: 0.5221 - val_accuracy: 0.7344\n",
      "Epoch 45/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5338 - accuracy: 0.7312 - val_loss: 0.5397 - val_accuracy: 0.7188\n",
      "Epoch 46/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5637 - accuracy: 0.7063 - val_loss: 0.5211 - val_accuracy: 0.7422\n",
      "Epoch 47/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5369 - accuracy: 0.7469 - val_loss: 0.5989 - val_accuracy: 0.6367\n",
      "Epoch 48/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5189 - accuracy: 0.7484 - val_loss: 0.5251 - val_accuracy: 0.7383\n",
      "Epoch 49/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5326 - accuracy: 0.7547 - val_loss: 0.5119 - val_accuracy: 0.7812\n",
      "Epoch 50/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5967 - accuracy: 0.6953 - val_loss: 0.5517 - val_accuracy: 0.7188\n",
      "Epoch 51/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7703 - val_loss: 0.5489 - val_accuracy: 0.7031\n",
      "Epoch 52/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5431 - accuracy: 0.7375 - val_loss: 0.5787 - val_accuracy: 0.7031\n",
      "Epoch 53/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5119 - accuracy: 0.7469 - val_loss: 0.5214 - val_accuracy: 0.7383\n",
      "Epoch 54/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5186 - accuracy: 0.7703 - val_loss: 0.4977 - val_accuracy: 0.7539\n",
      "Epoch 55/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5143 - accuracy: 0.7469 - val_loss: 0.6412 - val_accuracy: 0.7070\n",
      "Epoch 56/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5223 - accuracy: 0.7672 - val_loss: 0.5370 - val_accuracy: 0.7266\n",
      "Epoch 57/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5161 - accuracy: 0.7563 - val_loss: 0.5043 - val_accuracy: 0.7383\n",
      "Epoch 58/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5373 - accuracy: 0.7453 - val_loss: 0.5199 - val_accuracy: 0.7383\n",
      "Epoch 59/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5690 - accuracy: 0.7250 - val_loss: 0.5056 - val_accuracy: 0.7773\n",
      "Epoch 60/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4917 - accuracy: 0.7828 - val_loss: 0.5048 - val_accuracy: 0.7500\n",
      "Epoch 61/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5254 - accuracy: 0.7625 - val_loss: 0.5029 - val_accuracy: 0.7578\n",
      "Epoch 62/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5274 - accuracy: 0.7688 - val_loss: 0.5023 - val_accuracy: 0.7383\n",
      "Epoch 63/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5110 - accuracy: 0.7578 - val_loss: 0.5036 - val_accuracy: 0.7500\n",
      "Epoch 64/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5350 - accuracy: 0.7250 - val_loss: 0.4989 - val_accuracy: 0.7656\n",
      "Epoch 65/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5330 - accuracy: 0.7531 - val_loss: 0.5039 - val_accuracy: 0.7773\n",
      "Epoch 66/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5224 - accuracy: 0.7578 - val_loss: 0.4970 - val_accuracy: 0.7734\n",
      "Epoch 67/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5275 - accuracy: 0.7422 - val_loss: 0.5336 - val_accuracy: 0.7070\n",
      "Epoch 68/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5313 - accuracy: 0.7484 - val_loss: 0.5039 - val_accuracy: 0.7891\n",
      "Epoch 69/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5310 - accuracy: 0.7422 - val_loss: 0.5013 - val_accuracy: 0.7578\n",
      "Epoch 70/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5606 - accuracy: 0.7547 - val_loss: 0.6321 - val_accuracy: 0.7109\n",
      "Epoch 71/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5452 - accuracy: 0.7281 - val_loss: 0.5178 - val_accuracy: 0.7969\n",
      "Epoch 72/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5363 - accuracy: 0.7359 - val_loss: 0.5449 - val_accuracy: 0.7227\n",
      "Epoch 73/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5019 - accuracy: 0.7781 - val_loss: 0.5117 - val_accuracy: 0.7461\n",
      "Epoch 74/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5338 - accuracy: 0.7469 - val_loss: 0.6010 - val_accuracy: 0.7109\n",
      "Epoch 75/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5393 - accuracy: 0.7469 - val_loss: 0.5319 - val_accuracy: 0.7422\n",
      "Epoch 76/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5302 - accuracy: 0.7625 - val_loss: 0.5990 - val_accuracy: 0.7031\n",
      "Epoch 77/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5184 - accuracy: 0.7875 - val_loss: 0.5088 - val_accuracy: 0.7461\n",
      "Epoch 78/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5353 - accuracy: 0.7578 - val_loss: 0.9163 - val_accuracy: 0.4961\n",
      "Epoch 79/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5321 - accuracy: 0.7453 - val_loss: 0.4935 - val_accuracy: 0.7656\n",
      "Epoch 80/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5702 - accuracy: 0.7219 - val_loss: 0.5670 - val_accuracy: 0.7188\n",
      "Epoch 81/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5357 - accuracy: 0.7234 - val_loss: 0.5057 - val_accuracy: 0.7461\n",
      "Epoch 82/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7531 - val_loss: 0.5319 - val_accuracy: 0.7070\n",
      "Epoch 83/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5402 - accuracy: 0.7578 - val_loss: 0.4912 - val_accuracy: 0.7500\n",
      "Epoch 84/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4974 - accuracy: 0.7734 - val_loss: 0.5175 - val_accuracy: 0.7305\n",
      "Epoch 85/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5301 - accuracy: 0.7641 - val_loss: 0.4987 - val_accuracy: 0.7617\n",
      "Epoch 86/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5319 - accuracy: 0.7375 - val_loss: 0.5661 - val_accuracy: 0.7148\n",
      "Epoch 87/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4753 - accuracy: 0.7984 - val_loss: 0.4945 - val_accuracy: 0.7422\n",
      "Epoch 88/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5120 - accuracy: 0.7719 - val_loss: 0.5021 - val_accuracy: 0.7578\n",
      "Epoch 89/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5496 - accuracy: 0.7234 - val_loss: 0.5136 - val_accuracy: 0.7383\n",
      "Epoch 90/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5186 - accuracy: 0.7547 - val_loss: 0.5655 - val_accuracy: 0.7500\n",
      "Epoch 91/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5124 - accuracy: 0.7469 - val_loss: 0.4924 - val_accuracy: 0.7461\n",
      "Epoch 92/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4947 - accuracy: 0.7750 - val_loss: 0.5667 - val_accuracy: 0.7344\n",
      "Epoch 93/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5275 - accuracy: 0.7469 - val_loss: 0.5407 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4856 - accuracy: 0.7844 - val_loss: 0.5837 - val_accuracy: 0.7070\n",
      "Epoch 95/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5264 - accuracy: 0.7625 - val_loss: 0.5488 - val_accuracy: 0.6719\n",
      "Epoch 96/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5082 - accuracy: 0.7469 - val_loss: 0.6018 - val_accuracy: 0.7109\n",
      "Epoch 97/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4902 - accuracy: 0.7922 - val_loss: 0.4914 - val_accuracy: 0.7500\n",
      "Epoch 98/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4735 - accuracy: 0.7984 - val_loss: 0.4899 - val_accuracy: 0.7461\n",
      "Epoch 99/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2000 batches). You may need to use the repeat() function when building your dataset.\n",
      " 0/20 [..............................] - 0s 0s/step - loss: 0.4735 - accuracy: 0.7984 - val_loss: 0.4899 - val_accuracy: 0.7461\n"
     ]
    }
   ],
   "source": [
    "# 1. model.fit\n",
    "# 2. model ->estimator -> train\n",
    "\n",
    "train_dataset = make_dataset(train_df, y_train, epochs = 100)\n",
    "eval_dataset = make_dataset(eval_df, y_eval, epochs=1, shuffle=False)\n",
    "history = model.fit(train_dataset, validation_data=eval_dataset,\n",
    "                   steps_per_epoch=20,\n",
    "                   validation_steps=8,\n",
    "                   epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp8yqu0l4q\n",
      "INFO:tensorflow:Using the Keras model provided.\n",
      "WARNING:tensorflow:You are creating an Estimator from a Keras model manually subclassed from `Model`, that was already called on some inputs (and thus already had weights). We are currently unable to preserve the model's state (its weights) as part of the estimator in this case. Be warned that the estimator has been created using a freshly initialized version of your model.\n",
      "Note that this doesn't affect the state of the model instance you passed as `keras_model` argument.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp8yqu0l4q', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/keras.py:220: set_learning_phase (from tensorflow.python.keras.backend) is deprecated and will be removed after 2020-10-11.\n",
      "Instructions for updating:\n",
      "Simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unexpectedly found an instance of type `<class 'dict'>`. Expected a symbolic tensor instance.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-602f2146b076>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# 1. function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# 2. return a. (features, lables) b.dataset -> (feture, label)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m estimator.train(input_fn = lambda : make_dataset(\n\u001b[0m\u001b[1;32m      5\u001b[0m     train_df, y_train, epochs = 100))\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1173\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1175\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1202\u001b[0m       \u001b[0mworker_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1203\u001b[0m       estimator_spec = self._call_model_fn(features, labels, ModeKeys.TRAIN,\n\u001b[0;32m-> 1204\u001b[0;31m                                            self.config)\n\u001b[0m\u001b[1;32m   1205\u001b[0m       \u001b[0mglobal_step_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_global_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_call_model_fn\u001b[0;34m(self, features, labels, mode, config)\u001b[0m\n\u001b[1;32m   1161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Calling model_fn.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1163\u001b[0;31m     \u001b[0mmodel_fn_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1164\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Done calling model_fn.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/keras.py\u001b[0m in \u001b[0;36mmodel_fn\u001b[0;34m(features, labels, mode)\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         optimizer_config=optimizer_config)\n\u001b[0m\u001b[1;32m    330\u001b[0m     \u001b[0mmodel_output_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m     \u001b[0;31m# We need to make sure that the output names of the last layer in the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/keras.py\u001b[0m in \u001b[0;36m_clone_and_build_model\u001b[0;34m(mode, keras_model, custom_objects, features, labels, optimizer_config)\u001b[0m\n\u001b[1;32m    239\u001b[0m       \u001b[0min_place_reset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mkeras_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_graph_network\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m       \u001b[0moptimizer_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m       optimizer_config=optimizer_config)\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0msample_weight_tensors\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/models.py\u001b[0m in \u001b[0;36mclone_and_build_model\u001b[0;34m(model, input_tensors, target_tensors, custom_objects, compile_clone, in_place_reset, optimizer_iterations, optimizer_config)\u001b[0m\n\u001b[1;32m    648\u001b[0m       \u001b[0mclone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 650\u001b[0;31m       \u001b[0mclone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    651\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_graph_network\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_input_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly_outside_functions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/models.py\u001b[0m in \u001b[0;36mclone_model\u001b[0;34m(model, input_tensors, clone_function)\u001b[0m\n\u001b[1;32m    424\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m     return _clone_sequential_model(\n\u001b[0;32m--> 426\u001b[0;31m         model, input_tensors=input_tensors, layer_fn=clone_function)\n\u001b[0m\u001b[1;32m    427\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     return _clone_functional_model(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/models.py\u001b[0m in \u001b[0;36m_clone_sequential_model\u001b[0;34m(model, input_tensors, layer_fn)\u001b[0m\n\u001b[1;32m    343\u001b[0m       \u001b[0minput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgeneric_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_keras_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m       \u001b[0morigin_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morigin_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInputLayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mis_keras_tensor\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1135\u001b[0m                      sparse_tensor.SparseTensor, ragged_tensor.RaggedTensor)):\n\u001b[1;32m   1136\u001b[0m     raise ValueError('Unexpectedly found an instance of type `' + str(type(x)) +\n\u001b[0;32m-> 1137\u001b[0;31m                      '`. Expected a symbolic tensor instance.')\n\u001b[0m\u001b[1;32m   1138\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_keras_history'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unexpectedly found an instance of type `<class 'dict'>`. Expected a symbolic tensor instance."
     ]
    }
   ],
   "source": [
    "estimator = keras.estimator.model_to_estimator(model)\n",
    "# 1. function\n",
    "# 2. return a. (features, lables) b.dataset -> (feture, label)\n",
    "estimator.train(input_fn = lambda : make_dataset(\n",
    "    train_df, y_train, epochs = 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
